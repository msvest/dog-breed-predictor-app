{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Dog Breed Classifier CNN\n",
    "\n",
    "This notebook uses transfer learning to train an Xception CNN to predict dog breed from an image. The best weights found in this script will be saved and used by the web app implementation of this algorithm.\n",
    "\n",
    "This code is extracted from the full Dog Breed CNN project, which can be found here: ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('dog_breed_app/static/img/dogImages/train')\n",
    "valid_files, valid_targets = load_dataset('dog_breed_app/static/img/dogImages/valid')\n",
    "test_files, test_targets = load_dataset('dog_breed_app/static/img/dogImages/test')\n",
    "\n",
    "# load list of dog names\n",
    "dog_names = [item[20:-1] for item in sorted(glob(\"dog_breed_app/static/img/dogImages/train/*/\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to process images\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in img_paths]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bottleneck features for Xception model\n",
    "bottleneck_features = np.load('Code/Supporting Files/DogXceptionData.npz')\n",
    "train_Xception = bottleneck_features['train']\n",
    "valid_Xception = bottleneck_features['valid']\n",
    "test_Xception = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7, 2048)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Xception.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 133)               272517    \n",
      "=================================================================\n",
      "Total params: 272,517\n",
      "Trainable params: 272,517\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Xception model architecture\n",
    "Xception_model = Sequential()\n",
    "Xception_model.add(GlobalAveragePooling2D(input_shape=train_Xception.shape[1:]))\n",
    "Xception_model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "Xception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "Xception_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miika/anaconda3/envs/DogBreed/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:940: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (6680, 7, 7, 2048) (2048 channels).\n",
      "  ' channels).')\n",
      "/home/miika/anaconda3/envs/DogBreed/lib/python3.7/site-packages/keras_preprocessing/image/numpy_array_iterator.py:127: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (6680, 7, 7, 2048) (2048 channels).\n",
      "  str(self.x.shape[channels_axis]) + ' channels).')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "208/208 [==============================] - 283s 1s/step - loss: 1.1773 - accuracy: 0.7241 - val_loss: 0.5327 - val_accuracy: 0.8383\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.53271, saving model to Code/Supporting Files/weights.best.Xception.hdf5\n",
      "Epoch 2/10\n",
      "208/208 [==============================] - 284s 1s/step - loss: 0.4087 - accuracy: 0.8747 - val_loss: 0.4855 - val_accuracy: 0.8527\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.53271 to 0.48554, saving model to Code/Supporting Files/weights.best.Xception.hdf5\n",
      "Epoch 3/10\n",
      "208/208 [==============================] - 285s 1s/step - loss: 0.3175 - accuracy: 0.9004 - val_loss: 0.4378 - val_accuracy: 0.8563\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.48554 to 0.43777, saving model to Code/Supporting Files/weights.best.Xception.hdf5\n",
      "Epoch 4/10\n",
      "208/208 [==============================] - 286s 1s/step - loss: 0.2641 - accuracy: 0.9167 - val_loss: 0.4673 - val_accuracy: 0.8503\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.43777\n",
      "Epoch 5/10\n",
      "208/208 [==============================] - 286s 1s/step - loss: 0.2197 - accuracy: 0.9305 - val_loss: 0.4872 - val_accuracy: 0.8611\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.43777\n",
      "Epoch 6/10\n",
      "208/208 [==============================] - 286s 1s/step - loss: 0.2006 - accuracy: 0.9359 - val_loss: 0.4759 - val_accuracy: 0.8623\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.43777\n",
      "Epoch 7/10\n",
      "208/208 [==============================] - 285s 1s/step - loss: 0.1714 - accuracy: 0.9449 - val_loss: 0.5024 - val_accuracy: 0.8575\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.43777\n",
      "Epoch 8/10\n",
      "208/208 [==============================] - 285s 1s/step - loss: 0.1552 - accuracy: 0.9502 - val_loss: 0.4894 - val_accuracy: 0.8659\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.43777\n",
      "Epoch 9/10\n",
      "208/208 [==============================] - 287s 1s/step - loss: 0.1340 - accuracy: 0.9594 - val_loss: 0.4898 - val_accuracy: 0.8599\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.43777\n",
      "Epoch 10/10\n",
      "208/208 [==============================] - 286s 1s/step - loss: 0.1154 - accuracy: 0.9627 - val_loss: 0.5233 - val_accuracy: 0.8539\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.43777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f7348764d50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             rotation_range=30)\n",
    "\n",
    "datagen.fit(train_Xception)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='Code/Supporting Files/weights.best.Xception.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "Xception_model.fit_generator(datagen.flow(train_Xception, train_targets, batch_size=32),\n",
    "                    steps_per_epoch=train_Xception.shape[0] // 32,\n",
    "                    validation_data=(valid_Xception, valid_targets),\n",
    "                    epochs=epochs, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model with best weights for testing\n",
    "\n",
    "Xception_model.load_weights('Code/Supporting Files/weights.best.Xception.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 84.8086%\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "\n",
    "# get index of predicted dog breed for each image in test set\n",
    "Xception_predictions = [np.argmax(Xception_model.predict(np.expand_dims(feature, axis=0))) for feature in test_Xception]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(Xception_predictions)==np.argmax(test_targets, axis=1))/len(Xception_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
